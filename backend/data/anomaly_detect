import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns

# Load and clean data
df = pd.read_csv("backend/data/cleaned_billing_data.csv")
df['fresh_water_usage'] = pd.to_numeric(df['fresh_water_usage'], errors='coerce')
df['waste_water_usage'] = pd.to_numeric(df['waste_water_usage'], errors='coerce')
df['latest_charges'] = pd.to_numeric(df['latest_charges'], errors='coerce')
df['number_of_bedrooms'] = pd.to_numeric(df.get('number_of_bedrooms', np.nan), errors='coerce')
df['customer_id'] = df['account_number']
df['total_water_usage'] = df['fresh_water_usage'] + df['waste_water_usage']
df.dropna(subset=['total_water_usage', 'latest_charges'], inplace=True)

core_features = ['total_water_usage', 'latest_charges']

# Split customers by number of bills
bill_counts = df.groupby('customer_id').size()
high_customers = bill_counts[bill_counts >= 3].index
low_customers = bill_counts[bill_counts < 3].index

all_scored_rows = []

### 1. High-bill customers (analyze per customer)
for cust_id in high_customers:
    cust_df = df[df['customer_id'] == cust_id].copy()
    if len(cust_df) < 3:
        continue

    X = cust_df[core_features]
    model = IsolationForest(n_estimators=100, contamination='auto', random_state=42)
    model.fit(X)
    scores = model.decision_function(X)
    cust_df['anomaly_score'] = scores
    all_scored_rows.append(cust_df)

### 2. Low-bill customers (clustered)
df_low = df[df['customer_id'].isin(low_customers)].copy()
if not df_low.empty:
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(df_low[core_features])
    kmeans = KMeans(n_clusters=3, random_state=42)
    df_low['cluster'] = kmeans.fit_predict(X_scaled)
    
    for cluster in df_low['cluster'].unique():
        cluster_df = df_low[df_low['cluster'] == cluster].copy()
        X_cluster = cluster_df[core_features]
        model = IsolationForest(n_estimators=100, contamination='auto', random_state=42)
        model.fit(X_cluster)
        scores = model.decision_function(X_cluster)
        cluster_df['anomaly_score'] = scores
        all_scored_rows.append(cluster_df)

### 3. Combine all scored data
df_all = pd.concat(all_scored_rows, ignore_index=True)

# Visualize anomaly score distribution
plt.figure(figsize=(10, 4))
sns.histplot(df_all['anomaly_score'], bins=50, kde=True)
plt.title('Anomaly Score Distribution')
plt.xlabel('Anomaly Score (lower = more anomalous)')
plt.tight_layout()
plt.show()

# Decide threshold â€” e.g., bottom 3% are anomalies
threshold = df_all['anomaly_score'].quantile(0.03)
df_all['anomaly_flag'] = (df_all['anomaly_score'] < threshold).astype(int)

# Save results
df_all.to_csv("full_billing_anomaly_output.csv", index=False)
df_all[df_all['anomaly_flag'] == 1].to_csv("anomalies_only.csv", index=False)
